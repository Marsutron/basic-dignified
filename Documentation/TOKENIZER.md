# Tokenizer    Tokenize **ASCII** MSX Basic programs.    **Besides** the tokenization, MSX Basic Tokenizer can **export** a **list file** similar to ones on **Assemblers** with the **tokens** alongside the **ASCII** code and some statistics.      The format of each line is:  ```  80da: ee80 7800 44 49 ef 50 49 f2 1f 41 31 41 59 26 53 60 00 00        120 DI=PI-3.1415926536  [-1-] [---2---] [----------------------3----------------------]        [---------4----------]  ```  1. *Bytes 1-2*: The MSX Basic **memory** address of the line.  2. *Bytes 3-6*: The first four bytes with the **next line** address and the **line number**.  3. *Bytes 7-...*: The **tokenized** line.  4. The line in **ASCII**.    > The `.lmx` file uses the same syntax highlight as the classic MSX Basic.    A byte by byte, line by line tokenization process can also be shown, i.e.:  ```BASIC  10 PRINT "WH"  20 GOTO 10  ```  Will output:  ```  |10 PRINT "WH"  0a00|PRINT "WH"  0a0091| "WH"  0a009120|"WH"  0a00912022|WH"  0a0091202257|H"  0a009120225748|"  0a00912022574822|  |20 GOTO 10  1400|GOTO 10  140089| 10  140089200e0a00|  ```    **MSX Basic Tokenizer** is part of the **Basic Dignified Suite** and is **controlled** by its **parent** programs but it can be controlled **independently** or even **moved outside** to be used as an **standalone** program.    ### Direct use    If running from the **Basic Dignified root** folder:  `python -m Modules.msx.msxbatoken <ASCII_CODE> [BINARY_CODE] [arguments]`    To use the tonekizer as a **standalone** program, **copy** the following files to a single **folder**:  `\BasicDignified\Modules\msx\msxbatoken.py`  `\BasicDignified\Modules\msx\msxbatoken_settings.py`  `\BasicDignified\Modules\msx\msxbatoken.ini`  `\BasicDignified\Modules\Support\infolog.py`    And run with:  `python msxbatoken.py <ASCII_CODE> [BINARY_CODE] [arguments]`    ## Configurable arguments    When using as part of the **Basic Dignified Suite** the **configurations** are best **left alone** to be defined by the **parent** programs. However, when using on a **standalone** fashion, configurations to the **behaviour** of the tokenizer can be **applied** on:    `code:` The **code itself**  (in `\BasicDignified\Modules\msx\msxbatoken_settings.py`).  `.ini:` The **.ini file**  (in `\BasicDignified\Modules\msx\msxbatoken.ini`).  `cmdl:` Through arguments on the **command line**.    Each method has a **priority** higher than the one before.    #### Arguments    - *Source file*  The **ASCII** file to tokenize.  `Default:` `""`  `code:` `self.file_load = ['ASCII_CODE']`  `.ini:` `file_load = [ASCII_CODE]`  `cmdl:` `<ASCII_CODE>`    - *Destination file*  The **tokenized** file to be saved.  `Default:` **none**  `code:` `self.file_save = ['BINARY_CODE']`  `.ini:` `file_save = [BINARY_CODE]`  `cmdl:` `[BINARY_CODE]`  If no destination is given, the source name will be used with the appropriate extension.    - *Delete Original:*  **Delete** the ASCII file **after** the tokenized version is successfully **saved**.  `Default:` `False`  `code:` `self.delete_original = [True|False]`  `.ini:` `delete_original = [True|False]`  `cmdl:` `-do`    - *Export List:*  Save the **list file**.  `Default:` `16`  `code:` `self.export_list = [#]`  `.ini:` `export_list = [#]`  `cmdl:` `-el <#>`  The number argument refers to the amount of bytes shown per line. If no number is given, the default is 16. The maximum is 32.    - *Verbose level*  Set the level of feedback given by the program.  `0` = silent, `1` = +erros, `2` = +warnings, `3` = +headers, `4` = +subheaders, `5` = +tokenization.  `Default:` `3`  `code:` `self.verbose_level = [#]`  `.ini:` `verbose_level = [#]`  `cmdl:` `-vb <#>`      ## Notes    MSX Basic Tokenizer was **tested** with over **100** random basic **programs** from **magazines** and **other sources** and some programs crated to **stress** the conversions, however there should be still some (several?) fringe cases not covered.  **Be careful.**    There are some known **discrepancies** between **MSX Basic Tokenizer** and the **MSX tokenization**, most of them regarding **errors** on the code. They are:  - MSX `&b` (binary notation) tokenizes anything after it as characters except when a tokenized command is reached. The implementation here only looks for 0 and 1, reverting back to the normal parsing when other characters are found.  - Spaces at the end of a line are removed. The MSX does not remove them if loading from an ASCII file, only if typed on the machine.  - The MSX seems to split overflowed numbers on branching instructions (preceded by `0e`), here it throw an error.  - Syntax errors generate wildly different results from the ones generated by the MSX.    Some **errors** on the code will **stop** the **conversion**:  - Line number too high, line number out of order, lines not starting with numbers, branching lines too high.  - Numbers bigger than their explicit type (in some cases they are converted up as per on the MSX.)    